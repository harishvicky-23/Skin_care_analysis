{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb6b18e-992f-4abd-b417-a44e17a20022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Skin Type Classification Accuracy: 0.6707818930041153\n",
      "\n",
      "ðŸ§¾ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dry       0.70      0.70      0.70       243\n",
      "      normal       0.65      0.59      0.62       243\n",
      "        oily       0.66      0.72      0.69       243\n",
      "\n",
      "    accuracy                           0.67       729\n",
      "   macro avg       0.67      0.67      0.67       729\n",
      "weighted avg       0.67      0.67      0.67       729\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['skin_type_scaler.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from skimage.feature import local_binary_pattern\n",
    "import mahotas\n",
    "import glob\n",
    "\n",
    "# === Local Paths ===\n",
    "skin_type_train_dir = # training path of dataset\n",
    "skin_type_valid_dir = # validation path of dataset \n",
    "\n",
    "# === Feature Extraction ===\n",
    "def extract_skin_features(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Color Histograms (RGB + HSV)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    color_feat = np.concatenate([\n",
    "        cv2.calcHist([img], [0, 1, 2], None, [8, 8, 8], [0,256,0,256,0,256]).flatten(),\n",
    "        cv2.calcHist([hsv], [0, 1, 2], None, [8, 8, 8], [0,180,0,256,0,256]).flatten()\n",
    "    ])\n",
    "\n",
    "    # Texture - LBP\n",
    "    lbp = local_binary_pattern(gray, P=8, R=1, method=\"uniform\")\n",
    "    lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), range=(0, 10))\n",
    "    lbp_hist = lbp_hist.astype(\"float\") / (lbp_hist.sum() + 1e-7)\n",
    "\n",
    "    # Texture - Haralick\n",
    "    haralick_feat = mahotas.features.haralick(gray).mean(axis=0)\n",
    "\n",
    "    return np.concatenate([color_feat, lbp_hist, haralick_feat])\n",
    "\n",
    "# === Dataset Loader ===\n",
    "def load_dataset(path, classes):\n",
    "    X, y = [], []\n",
    "    for i, label in enumerate(classes):\n",
    "        folder = os.path.join(path, label)\n",
    "        files = glob.glob(folder + '/*.jpg') + glob.glob(folder + '/*.png')\n",
    "        for file in files:\n",
    "            features = extract_skin_features(file)\n",
    "            if features is not None:\n",
    "                X.append(features)\n",
    "                y.append(i)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# === Load Skin Type Dataset ===\n",
    "skin_classes = ['dry', 'normal', 'oily']\n",
    "X_train_skin, y_train_skin = load_dataset(skin_type_train_dir, skin_classes)\n",
    "X_val_skin, y_val_skin = load_dataset(skin_type_valid_dir, skin_classes)\n",
    "\n",
    "# === Combine and Shuffle ===\n",
    "X_skin, y_skin = shuffle(np.concatenate([X_train_skin, X_val_skin]),\n",
    "                         np.concatenate([y_train_skin, y_val_skin]),\n",
    "                         random_state=42)\n",
    "\n",
    "# === SMOTE Balancing ===\n",
    "smote = SMOTE(random_state=42)\n",
    "X_bal, y_bal = smote.fit_resample(X_skin, y_skin)\n",
    "\n",
    "# === Scaling + PCA ===\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_bal)\n",
    "\n",
    "# Reduce dimensionality to improve speed + accuracy\n",
    "pca = PCA(n_components=100, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# === Train/Test Split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y_bal, test_size=0.2,\n",
    "                                                    stratify=y_bal, random_state=42)\n",
    "\n",
    "# === SVM with Grid Search ===\n",
    "param_grid = {'svc__C': [1, 10], 'svc__gamma': ['scale', 0.01]}\n",
    "svm_model = GridSearchCV(make_pipeline(StandardScaler(), SVC(kernel='rbf')), \n",
    "                         param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# === Evaluate ===\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(\"âœ… Skin Type Classification Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nðŸ§¾ Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=skin_classes))\n",
    "\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Save model components\n",
    "joblib.dump(svm_model, \"skin_type_svm_model.pkl\")\n",
    "joblib.dump(pca, \"skin_type_pca.pkl\")\n",
    "joblib.dump(scaler, \"skin_type_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1462c0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from skimage.feature import local_binary_pattern\n",
    "import mahotas\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfb064c-2d93-4f64-ab07-f3e58884a108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Predicted Skin Type: oily\n"
     ]
    }
   ],
   "source": [
    "def predict_skin_type(image_path):\n",
    "    # Load model components\n",
    "    model = joblib.load(\"models/models/skin_type_svm_model.pkl\")\n",
    "    pca = joblib.load(\"models/models/skin_type_pca.pkl\")\n",
    "    scaler = joblib.load(\"models/models/skin_type_scaler.pkl\")\n",
    "\n",
    "    # Class labels\n",
    "    skin_classes = ['dry', 'normal', 'oily']\n",
    "\n",
    "    # Extract features\n",
    "    features = extract_skin_features(image_path)\n",
    "    if features is None:\n",
    "        print(\"Image could not be loaded.\")\n",
    "        return\n",
    "\n",
    "    # Transform\n",
    "    features_scaled = scaler.transform([features])\n",
    "    features_pca = pca.transform(features_scaled)\n",
    "\n",
    "    # Predict\n",
    "    prediction = model.predict(features_pca)[0]\n",
    "    print(f\"ðŸ§  Predicted Skin Type: {skin_classes[prediction]}\")\n",
    "\n",
    "predict_skin_type(#sample input image path to predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad61d528-7e59-4b75-8220-9469d6044d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_skin_features(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Color Histograms (RGB + HSV)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    color_feat = np.concatenate([\n",
    "        cv2.calcHist([img], [0, 1, 2], None, [8, 8, 8], [0,256,0,256,0,256]).flatten(),\n",
    "        cv2.calcHist([hsv], [0, 1, 2], None, [8, 8, 8], [0,180,0,256,0,256]).flatten()\n",
    "    ])\n",
    "\n",
    "    # Texture - LBP\n",
    "    lbp = local_binary_pattern(gray, P=8, R=1, method=\"uniform\")\n",
    "    lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), range=(0, 10))\n",
    "    lbp_hist = lbp_hist.astype(\"float\") / (lbp_hist.sum() + 1e-7)\n",
    "\n",
    "    # Texture - Haralick\n",
    "    haralick_feat = mahotas.features.haralick(gray).mean(axis=0)\n",
    "\n",
    "    return np.concatenate([color_feat, lbp_hist, haralick_feat])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f907702b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "harish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
